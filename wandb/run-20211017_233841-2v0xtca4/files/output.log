[32m[10/17 23:38:47 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
  0%|                                                   | 0/559 [00:00<?, ?it/s]  6%|██▍                                      | 34/559 [00:00<00:01, 339.22it/s] 12%|█████                                    | 69/559 [00:00<00:01, 345.47it/s] 19%|███████▍                                | 104/559 [00:00<00:01, 344.08it/s] 25%|██████████▏                             | 142/559 [00:00<00:01, 356.85it/s] 32%|████████████▋                           | 178/559 [00:00<00:01, 357.58it/s] 38%|███████████████▎                        | 214/559 [00:00<00:00, 354.22it/s] 45%|█████████████████▉                      | 250/559 [00:00<00:00, 354.77it/s] 51%|████████████████████▍                   | 286/559 [00:00<00:00, 349.28it/s] 58%|███████████████████████                 | 323/559 [00:00<00:00, 353.61it/s] 65%|█████████████████████████▊              | 361/559 [00:01<00:00, 360.91it/s] 71%|████████████████████████████▌           | 399/559 [00:01<00:00, 363.78it/s] 78%|███████████████████████████████▏        | 436/559 [00:01<00:00, 357.05it/s] 84%|█████████████████████████████████▊      | 472/559 [00:01<00:00, 357.28it/s] 91%|████████████████████████████████████▎   | 508/559 [00:01<00:00, 354.60it/s] 97%|██████████████████████████████████████▉ | 544/559 [00:01<00:00, 351.92it/s]100%|████████████████████████████████████████| 559/559 [00:01<00:00, 353.50it/s]
[32m[10/17 23:38:48 d2.data.build]: [0mRemoved 0 images with no usable annotations. 559 images left.
[32m[10/17 23:38:48 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[10/17 23:38:48 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[10/17 23:38:48 d2.data.common]: [0mSerializing 559 elements to byte tensors and concatenating them all ...
[32m[10/17 23:38:48 d2.data.common]: [0mSerialized dataset takes 0.19 MiB
2021-10-17 23:38:49.673678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
The checkpoint state_dict contains keys that are not used by the model:
  [35mproposal_generator.anchor_generator.cell_anchors.0[0m
[32m[10/17 23:38:53 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[10/17 23:39:01 d2.utils.events]: [0m eta: 0:15:45  iter: 19  total_loss: 1.341  loss_cls: 0.8473  loss_box_reg: 0.4543  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.004875  time: 0.3798  data_time: 0.0153  lr: 4.9953e-06  max_mem: 2283M
[32m[10/17 23:39:08 d2.utils.events]: [0m eta: 0:15:17  iter: 39  total_loss: 1.23  loss_cls: 0.7416  loss_box_reg: 0.4363  loss_rpn_cls: 0.007718  loss_rpn_loc: 0.0059  time: 0.3710  data_time: 0.0026  lr: 9.9902e-06  max_mem: 2283M
[32m[10/17 23:39:16 d2.utils.events]: [0m eta: 0:15:09  iter: 59  total_loss: 1.036  loss_cls: 0.5696  loss_box_reg: 0.4776  loss_rpn_cls: 0.009914  loss_rpn_loc: 0.0048  time: 0.3711  data_time: 0.0027  lr: 1.4985e-05  max_mem: 2283M
[32m[10/17 23:39:23 d2.utils.events]: [0m eta: 0:15:03  iter: 79  total_loss: 0.8626  loss_cls: 0.4087  loss_box_reg: 0.4346  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.005369  time: 0.3731  data_time: 0.0028  lr: 1.998e-05  max_mem: 2283M
[32m[10/17 23:39:31 d2.utils.events]: [0m eta: 0:14:59  iter: 99  total_loss: 0.7408  loss_cls: 0.311  loss_box_reg: 0.3887  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.007403  time: 0.3746  data_time: 0.0027  lr: 2.4975e-05  max_mem: 2283M
[32m[10/17 23:39:39 d2.utils.events]: [0m eta: 0:14:52  iter: 119  total_loss: 0.6916  loss_cls: 0.2579  loss_box_reg: 0.4171  loss_rpn_cls: 0.005425  loss_rpn_loc: 0.003967  time: 0.3759  data_time: 0.0027  lr: 2.997e-05  max_mem: 2283M
[32m[10/17 23:39:46 d2.utils.events]: [0m eta: 0:14:49  iter: 139  total_loss: 0.6323  loss_cls: 0.2212  loss_box_reg: 0.4182  loss_rpn_cls: 0.004643  loss_rpn_loc: 0.003557  time: 0.3771  data_time: 0.0031  lr: 3.4965e-05  max_mem: 2283M
[32m[10/17 23:39:54 d2.utils.events]: [0m eta: 0:14:41  iter: 159  total_loss: 0.6159  loss_cls: 0.1964  loss_box_reg: 0.4051  loss_rpn_cls: 0.003674  loss_rpn_loc: 0.003495  time: 0.3769  data_time: 0.0026  lr: 3.996e-05  max_mem: 2283M
[32m[10/17 23:40:01 d2.utils.events]: [0m eta: 0:14:36  iter: 179  total_loss: 0.606  loss_cls: 0.1686  loss_box_reg: 0.4195  loss_rpn_cls: 0.003897  loss_rpn_loc: 0.003779  time: 0.3775  data_time: 0.0029  lr: 4.4955e-05  max_mem: 2283M
[32m[10/17 23:40:09 d2.utils.events]: [0m eta: 0:14:28  iter: 199  total_loss: 0.6497  loss_cls: 0.1655  loss_box_reg: 0.4579  loss_rpn_cls: 0.007461  loss_rpn_loc: 0.004865  time: 0.3769  data_time: 0.0026  lr: 4.995e-05  max_mem: 2283M
[32m[10/17 23:40:17 d2.utils.events]: [0m eta: 0:14:21  iter: 219  total_loss: 0.6227  loss_cls: 0.1422  loss_box_reg: 0.459  loss_rpn_cls: 0.004615  loss_rpn_loc: 0.003179  time: 0.3773  data_time: 0.0027  lr: 5.4945e-05  max_mem: 2283M
[32m[10/17 23:40:24 d2.utils.events]: [0m eta: 0:14:19  iter: 239  total_loss: 0.5675  loss_cls: 0.128  loss_box_reg: 0.4336  loss_rpn_cls: 0.004369  loss_rpn_loc: 0.003764  time: 0.3785  data_time: 0.0062  lr: 5.994e-05  max_mem: 2283M
[32m[10/17 23:40:33 d2.utils.events]: [0m eta: 0:14:13  iter: 259  total_loss: 0.5866  loss_cls: 0.1232  loss_box_reg: 0.4604  loss_rpn_cls: 0.004163  loss_rpn_loc: 0.003844  time: 0.3807  data_time: 0.0053  lr: 6.4935e-05  max_mem: 2283M
[32m[10/17 23:40:40 d2.utils.events]: [0m eta: 0:14:06  iter: 279  total_loss: 0.4886  loss_cls: 0.09937  loss_box_reg: 0.3744  loss_rpn_cls: 0.004523  loss_rpn_loc: 0.002565  time: 0.3807  data_time: 0.0032  lr: 6.993e-05  max_mem: 2283M
[32m[10/17 23:40:47 d2.utils.events]: [0m eta: 0:13:57  iter: 299  total_loss: 0.5735  loss_cls: 0.1177  loss_box_reg: 0.4404  loss_rpn_cls: 0.005712  loss_rpn_loc: 0.003117  time: 0.3797  data_time: 0.0031  lr: 7.4925e-05  max_mem: 2283M
[32m[10/17 23:40:55 d2.utils.events]: [0m eta: 0:13:45  iter: 319  total_loss: 0.4747  loss_cls: 0.07748  loss_box_reg: 0.3761  loss_rpn_cls: 0.0049  loss_rpn_loc: 0.002391  time: 0.3771  data_time: 0.0028  lr: 7.992e-05  max_mem: 2283M
[32m[10/17 23:41:01 d2.utils.events]: [0m eta: 0:13:34  iter: 339  total_loss: 0.5402  loss_cls: 0.08372  loss_box_reg: 0.4408  loss_rpn_cls: 0.003118  loss_rpn_loc: 0.003023  time: 0.3749  data_time: 0.0025  lr: 8.4915e-05  max_mem: 2283M
[32m[10/17 23:41:08 d2.utils.events]: [0m eta: 0:13:23  iter: 359  total_loss: 0.4975  loss_cls: 0.07578  loss_box_reg: 0.394  loss_rpn_cls: 0.004599  loss_rpn_loc: 0.002378  time: 0.3733  data_time: 0.0026  lr: 8.991e-05  max_mem: 2283M
[32m[10/17 23:41:15 d2.utils.events]: [0m eta: 0:13:13  iter: 379  total_loss: 0.4728  loss_cls: 0.07667  loss_box_reg: 0.3865  loss_rpn_cls: 0.002376  loss_rpn_loc: 0.002974  time: 0.3716  data_time: 0.0025  lr: 9.4905e-05  max_mem: 2283M
[32m[10/17 23:41:22 d2.utils.events]: [0m eta: 0:13:02  iter: 399  total_loss: 0.4931  loss_cls: 0.07489  loss_box_reg: 0.3918  loss_rpn_cls: 0.002613  loss_rpn_loc: 0.002535  time: 0.3703  data_time: 0.0027  lr: 9.99e-05  max_mem: 2283M
[32m[10/17 23:41:29 d2.utils.events]: [0m eta: 0:12:53  iter: 419  total_loss: 0.4311  loss_cls: 0.05577  loss_box_reg: 0.3564  loss_rpn_cls: 0.00228  loss_rpn_loc: 0.002785  time: 0.3691  data_time: 0.0027  lr: 0.0001049  max_mem: 2283M
[32m[10/17 23:41:36 d2.utils.events]: [0m eta: 0:12:39  iter: 439  total_loss: 0.4431  loss_cls: 0.06593  loss_box_reg: 0.3452  loss_rpn_cls: 0.003362  loss_rpn_loc: 0.003178  time: 0.3678  data_time: 0.0028  lr: 0.00010989  max_mem: 2283M
[32m[10/17 23:41:43 d2.utils.events]: [0m eta: 0:12:27  iter: 459  total_loss: 0.4091  loss_cls: 0.06057  loss_box_reg: 0.3236  loss_rpn_cls: 0.00362  loss_rpn_loc: 0.002848  time: 0.3667  data_time: 0.0026  lr: 0.00011489  max_mem: 2283M
[32m[10/17 23:41:50 d2.utils.events]: [0m eta: 0:12:14  iter: 479  total_loss: 0.3612  loss_cls: 0.04643  loss_box_reg: 0.3028  loss_rpn_cls: 0.001153  loss_rpn_loc: 0.00301  time: 0.3656  data_time: 0.0024  lr: 0.00011988  max_mem: 2283M
[32m[10/17 23:41:57 d2.utils.events]: [0m eta: 0:11:58  iter: 499  total_loss: 0.3354  loss_cls: 0.05858  loss_box_reg: 0.2451  loss_rpn_cls: 0.002759  loss_rpn_loc: 0.003177  time: 0.3647  data_time: 0.0025  lr: 0.00012488  max_mem: 2283M
[32m[10/17 23:42:04 d2.utils.events]: [0m eta: 0:11:47  iter: 519  total_loss: 0.3097  loss_cls: 0.05268  loss_box_reg: 0.2463  loss_rpn_cls: 0.003072  loss_rpn_loc: 0.002601  time: 0.3640  data_time: 0.0026  lr: 0.00012987  max_mem: 2283M
[32m[10/17 23:42:10 d2.utils.events]: [0m eta: 0:11:35  iter: 539  total_loss: 0.2763  loss_cls: 0.0585  loss_box_reg: 0.2112  loss_rpn_cls: 0.004784  loss_rpn_loc: 0.002625  time: 0.3633  data_time: 0.0026  lr: 0.00013487  max_mem: 2283M
[32m[10/17 23:42:17 d2.utils.events]: [0m eta: 0:11:27  iter: 559  total_loss: 0.2947  loss_cls: 0.0723  loss_box_reg: 0.2028  loss_rpn_cls: 0.001832  loss_rpn_loc: 0.002969  time: 0.3626  data_time: 0.0027  lr: 0.00013986  max_mem: 2283M
[32m[10/17 23:42:24 d2.utils.events]: [0m eta: 0:11:19  iter: 579  total_loss: 0.2705  loss_cls: 0.05787  loss_box_reg: 0.205  loss_rpn_cls: 0.00136  loss_rpn_loc: 0.002538  time: 0.3619  data_time: 0.0027  lr: 0.00014486  max_mem: 2283M
[32m[10/17 23:42:31 d2.utils.events]: [0m eta: 0:11:11  iter: 599  total_loss: 0.2762  loss_cls: 0.05002  loss_box_reg: 0.205  loss_rpn_cls: 0.002177  loss_rpn_loc: 0.002833  time: 0.3613  data_time: 0.0026  lr: 0.00014985  max_mem: 2283M
[32m[10/17 23:42:38 d2.utils.events]: [0m eta: 0:11:03  iter: 619  total_loss: 0.2324  loss_cls: 0.05391  loss_box_reg: 0.172  loss_rpn_cls: 0.002438  loss_rpn_loc: 0.002183  time: 0.3608  data_time: 0.0025  lr: 0.00015485  max_mem: 2283M
[32m[10/17 23:42:45 d2.utils.events]: [0m eta: 0:10:55  iter: 639  total_loss: 0.271  loss_cls: 0.05766  loss_box_reg: 0.2078  loss_rpn_cls: 0.00408  loss_rpn_loc: 0.003014  time: 0.3600  data_time: 0.0025  lr: 0.00015984  max_mem: 2283M
[32m[10/17 23:42:52 d2.utils.events]: [0m eta: 0:10:48  iter: 659  total_loss: 0.2382  loss_cls: 0.04861  loss_box_reg: 0.1783  loss_rpn_cls: 0.002897  loss_rpn_loc: 0.00256  time: 0.3596  data_time: 0.0025  lr: 0.00016484  max_mem: 2283M
[32m[10/17 23:42:59 d2.utils.events]: [0m eta: 0:10:41  iter: 679  total_loss: 0.2283  loss_cls: 0.05308  loss_box_reg: 0.1671  loss_rpn_cls: 0.003827  loss_rpn_loc: 0.002864  time: 0.3590  data_time: 0.0025  lr: 0.00016983  max_mem: 2283M
[32m[10/17 23:43:06 d2.utils.events]: [0m eta: 0:10:34  iter: 699  total_loss: 0.2347  loss_cls: 0.04707  loss_box_reg: 0.172  loss_rpn_cls: 0.001572  loss_rpn_loc: 0.003324  time: 0.3587  data_time: 0.0026  lr: 0.00017483  max_mem: 2283M
[32m[10/17 23:43:12 d2.utils.events]: [0m eta: 0:10:26  iter: 719  total_loss: 0.2573  loss_cls: 0.0435  loss_box_reg: 0.1949  loss_rpn_cls: 0.001417  loss_rpn_loc: 0.002507  time: 0.3583  data_time: 0.0027  lr: 0.00017982  max_mem: 2283M
[32m[10/17 23:43:19 d2.utils.events]: [0m eta: 0:10:19  iter: 739  total_loss: 0.2516  loss_cls: 0.0498  loss_box_reg: 0.1971  loss_rpn_cls: 0.002415  loss_rpn_loc: 0.003311  time: 0.3580  data_time: 0.0025  lr: 0.00018482  max_mem: 2283M
[32m[10/17 23:43:26 d2.utils.events]: [0m eta: 0:10:12  iter: 759  total_loss: 0.2509  loss_cls: 0.03985  loss_box_reg: 0.1762  loss_rpn_cls: 0.003324  loss_rpn_loc: 0.002999  time: 0.3577  data_time: 0.0026  lr: 0.00018981  max_mem: 2283M
[32m[10/17 23:43:33 d2.utils.events]: [0m eta: 0:10:05  iter: 779  total_loss: 0.2255  loss_cls: 0.04889  loss_box_reg: 0.1653  loss_rpn_cls: 0.001474  loss_rpn_loc: 0.00229  time: 0.3574  data_time: 0.0026  lr: 0.00019481  max_mem: 2283M
[32m[10/17 23:43:40 d2.utils.events]: [0m eta: 0:09:57  iter: 799  total_loss: 0.2646  loss_cls: 0.05947  loss_box_reg: 0.1935  loss_rpn_cls: 0.00308  loss_rpn_loc: 0.002858  time: 0.3571  data_time: 0.0025  lr: 0.0001998  max_mem: 2283M
[32m[10/17 23:43:47 d2.utils.events]: [0m eta: 0:09:50  iter: 819  total_loss: 0.2274  loss_cls: 0.057  loss_box_reg: 0.1765  loss_rpn_cls: 0.001393  loss_rpn_loc: 0.002504  time: 0.3569  data_time: 0.0026  lr: 0.0002048  max_mem: 2283M
[32m[10/17 23:43:54 d2.utils.events]: [0m eta: 0:09:43  iter: 839  total_loss: 0.2269  loss_cls: 0.0361  loss_box_reg: 0.1696  loss_rpn_cls: 0.0008387  loss_rpn_loc: 0.00227  time: 0.3565  data_time: 0.0024  lr: 0.00020979  max_mem: 2283M
[32m[10/17 23:44:01 d2.utils.events]: [0m eta: 0:09:36  iter: 859  total_loss: 0.2436  loss_cls: 0.0466  loss_box_reg: 0.1943  loss_rpn_cls: 0.002143  loss_rpn_loc: 0.002002  time: 0.3562  data_time: 0.0026  lr: 0.00021479  max_mem: 2283M
[32m[10/17 23:44:08 d2.utils.events]: [0m eta: 0:09:29  iter: 879  total_loss: 0.2122  loss_cls: 0.04459  loss_box_reg: 0.1664  loss_rpn_cls: 0.001026  loss_rpn_loc: 0.002839  time: 0.3560  data_time: 0.0026  lr: 0.00021978  max_mem: 2283M
[32m[10/17 23:44:15 d2.utils.events]: [0m eta: 0:09:21  iter: 899  total_loss: 0.2405  loss_cls: 0.05068  loss_box_reg: 0.1784  loss_rpn_cls: 0.001601  loss_rpn_loc: 0.002807  time: 0.3557  data_time: 0.0025  lr: 0.00022478  max_mem: 2283M
[32m[10/17 23:44:22 d2.utils.events]: [0m eta: 0:09:14  iter: 919  total_loss: 0.2387  loss_cls: 0.0524  loss_box_reg: 0.1781  loss_rpn_cls: 0.002342  loss_rpn_loc: 0.002328  time: 0.3554  data_time: 0.0025  lr: 0.00022977  max_mem: 2283M
[32m[10/17 23:44:28 d2.utils.events]: [0m eta: 0:09:07  iter: 939  total_loss: 0.2383  loss_cls: 0.05479  loss_box_reg: 0.1654  loss_rpn_cls: 0.002348  loss_rpn_loc: 0.00224  time: 0.3551  data_time: 0.0024  lr: 0.00023477  max_mem: 2283M
[32m[10/17 23:44:35 d2.utils.events]: [0m eta: 0:09:00  iter: 959  total_loss: 0.2411  loss_cls: 0.05761  loss_box_reg: 0.1633  loss_rpn_cls: 0.001731  loss_rpn_loc: 0.002489  time: 0.3549  data_time: 0.0025  lr: 0.00023976  max_mem: 2283M
[32m[10/17 23:44:42 d2.utils.events]: [0m eta: 0:08:53  iter: 979  total_loss: 0.2074  loss_cls: 0.05142  loss_box_reg: 0.1539  loss_rpn_cls: 0.005301  loss_rpn_loc: 0.001825  time: 0.3546  data_time: 0.0025  lr: 0.00024476  max_mem: 2283M
[32m[10/17 23:44:49 d2.utils.events]: [0m eta: 0:08:45  iter: 999  total_loss: 0.2305  loss_cls: 0.04957  loss_box_reg: 0.1688  loss_rpn_cls: 0.001751  loss_rpn_loc: 0.002976  time: 0.3545  data_time: 0.0025  lr: 0.00024975  max_mem: 2283M
[32m[10/17 23:44:56 d2.utils.events]: [0m eta: 0:08:38  iter: 1019  total_loss: 0.2237  loss_cls: 0.05336  loss_box_reg: 0.1787  loss_rpn_cls: 0.0007466  loss_rpn_loc: 0.00252  time: 0.3542  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:03 d2.utils.events]: [0m eta: 0:08:31  iter: 1039  total_loss: 0.2393  loss_cls: 0.05462  loss_box_reg: 0.1554  loss_rpn_cls: 0.002955  loss_rpn_loc: 0.002499  time: 0.3540  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:10 d2.utils.events]: [0m eta: 0:08:24  iter: 1059  total_loss: 0.247  loss_cls: 0.06103  loss_box_reg: 0.171  loss_rpn_cls: 0.002079  loss_rpn_loc: 0.002883  time: 0.3537  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:17 d2.utils.events]: [0m eta: 0:08:16  iter: 1079  total_loss: 0.238  loss_cls: 0.0409  loss_box_reg: 0.1751  loss_rpn_cls: 0.00153  loss_rpn_loc: 0.002808  time: 0.3535  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:24 d2.utils.events]: [0m eta: 0:08:09  iter: 1099  total_loss: 0.2239  loss_cls: 0.05568  loss_box_reg: 0.1698  loss_rpn_cls: 0.001953  loss_rpn_loc: 0.002151  time: 0.3534  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:31 d2.utils.events]: [0m eta: 0:08:02  iter: 1119  total_loss: 0.2142  loss_cls: 0.04277  loss_box_reg: 0.1592  loss_rpn_cls: 0.0008413  loss_rpn_loc: 0.001881  time: 0.3532  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:38 d2.utils.events]: [0m eta: 0:07:55  iter: 1139  total_loss: 0.2664  loss_cls: 0.05923  loss_box_reg: 0.1766  loss_rpn_cls: 0.0007401  loss_rpn_loc: 0.002729  time: 0.3531  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:45 d2.utils.events]: [0m eta: 0:07:48  iter: 1159  total_loss: 0.2204  loss_cls: 0.04359  loss_box_reg: 0.1617  loss_rpn_cls: 0.001709  loss_rpn_loc: 0.00167  time: 0.3530  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:51 d2.utils.events]: [0m eta: 0:07:41  iter: 1179  total_loss: 0.2451  loss_cls: 0.05283  loss_box_reg: 0.1726  loss_rpn_cls: 0.001304  loss_rpn_loc: 0.003072  time: 0.3528  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:45:58 d2.utils.events]: [0m eta: 0:07:34  iter: 1199  total_loss: 0.2537  loss_cls: 0.06665  loss_box_reg: 0.1874  loss_rpn_cls: 0.001301  loss_rpn_loc: 0.002406  time: 0.3527  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:05 d2.utils.events]: [0m eta: 0:07:26  iter: 1219  total_loss: 0.2158  loss_cls: 0.04713  loss_box_reg: 0.1628  loss_rpn_cls: 0.0007024  loss_rpn_loc: 0.002096  time: 0.3526  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:12 d2.utils.events]: [0m eta: 0:07:19  iter: 1239  total_loss: 0.259  loss_cls: 0.06241  loss_box_reg: 0.1904  loss_rpn_cls: 0.0007796  loss_rpn_loc: 0.002718  time: 0.3525  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:19 d2.utils.events]: [0m eta: 0:07:12  iter: 1259  total_loss: 0.2626  loss_cls: 0.05879  loss_box_reg: 0.1974  loss_rpn_cls: 0.000966  loss_rpn_loc: 0.002549  time: 0.3525  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:26 d2.utils.events]: [0m eta: 0:07:05  iter: 1279  total_loss: 0.266  loss_cls: 0.06446  loss_box_reg: 0.1774  loss_rpn_cls: 0.000761  loss_rpn_loc: 0.002846  time: 0.3524  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:33 d2.utils.events]: [0m eta: 0:06:58  iter: 1299  total_loss: 0.2169  loss_cls: 0.04621  loss_box_reg: 0.1539  loss_rpn_cls: 0.0005644  loss_rpn_loc: 0.002213  time: 0.3521  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:40 d2.utils.events]: [0m eta: 0:06:51  iter: 1319  total_loss: 0.2201  loss_cls: 0.05491  loss_box_reg: 0.1679  loss_rpn_cls: 0.0007287  loss_rpn_loc: 0.002113  time: 0.3520  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:47 d2.utils.events]: [0m eta: 0:06:44  iter: 1339  total_loss: 0.2121  loss_cls: 0.05262  loss_box_reg: 0.1549  loss_rpn_cls: 0.001362  loss_rpn_loc: 0.00224  time: 0.3521  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:46:54 d2.utils.events]: [0m eta: 0:06:37  iter: 1359  total_loss: 0.2326  loss_cls: 0.04605  loss_box_reg: 0.1704  loss_rpn_cls: 0.0007041  loss_rpn_loc: 0.002354  time: 0.3520  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:01 d2.utils.events]: [0m eta: 0:06:30  iter: 1379  total_loss: 0.2634  loss_cls: 0.06641  loss_box_reg: 0.185  loss_rpn_cls: 0.001209  loss_rpn_loc: 0.00193  time: 0.3519  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:08 d2.utils.events]: [0m eta: 0:06:23  iter: 1399  total_loss: 0.2368  loss_cls: 0.05381  loss_box_reg: 0.1669  loss_rpn_cls: 0.001231  loss_rpn_loc: 0.002294  time: 0.3518  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:15 d2.utils.events]: [0m eta: 0:06:16  iter: 1419  total_loss: 0.2473  loss_cls: 0.05212  loss_box_reg: 0.1721  loss_rpn_cls: 0.001692  loss_rpn_loc: 0.002484  time: 0.3518  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:22 d2.utils.events]: [0m eta: 0:06:09  iter: 1439  total_loss: 0.2324  loss_cls: 0.04539  loss_box_reg: 0.1848  loss_rpn_cls: 0.0009583  loss_rpn_loc: 0.002325  time: 0.3517  data_time: 0.0028  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:29 d2.utils.events]: [0m eta: 0:06:02  iter: 1459  total_loss: 0.2159  loss_cls: 0.05673  loss_box_reg: 0.1478  loss_rpn_cls: 0.002017  loss_rpn_loc: 0.002539  time: 0.3516  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:35 d2.utils.events]: [0m eta: 0:05:55  iter: 1479  total_loss: 0.2466  loss_cls: 0.04825  loss_box_reg: 0.1843  loss_rpn_cls: 0.001829  loss_rpn_loc: 0.002644  time: 0.3514  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:42 d2.utils.events]: [0m eta: 0:05:48  iter: 1499  total_loss: 0.2333  loss_cls: 0.04392  loss_box_reg: 0.1721  loss_rpn_cls: 0.000957  loss_rpn_loc: 0.002625  time: 0.3513  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:49 d2.utils.events]: [0m eta: 0:05:41  iter: 1519  total_loss: 0.269  loss_cls: 0.06387  loss_box_reg: 0.1732  loss_rpn_cls: 0.001264  loss_rpn_loc: 0.002497  time: 0.3512  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:47:56 d2.utils.events]: [0m eta: 0:05:34  iter: 1539  total_loss: 0.2411  loss_cls: 0.05475  loss_box_reg: 0.1809  loss_rpn_cls: 0.00111  loss_rpn_loc: 0.002644  time: 0.3512  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:03 d2.utils.events]: [0m eta: 0:05:27  iter: 1559  total_loss: 0.2401  loss_cls: 0.07665  loss_box_reg: 0.1838  loss_rpn_cls: 0.0006979  loss_rpn_loc: 0.002155  time: 0.3511  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:10 d2.utils.events]: [0m eta: 0:05:20  iter: 1579  total_loss: 0.2467  loss_cls: 0.05796  loss_box_reg: 0.1675  loss_rpn_cls: 0.002987  loss_rpn_loc: 0.001991  time: 0.3510  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:17 d2.utils.events]: [0m eta: 0:05:14  iter: 1599  total_loss: 0.2359  loss_cls: 0.05128  loss_box_reg: 0.1808  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.002603  time: 0.3510  data_time: 0.0031  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:24 d2.utils.events]: [0m eta: 0:05:07  iter: 1619  total_loss: 0.2512  loss_cls: 0.05945  loss_box_reg: 0.1777  loss_rpn_cls: 0.0009768  loss_rpn_loc: 0.002572  time: 0.3510  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:31 d2.utils.events]: [0m eta: 0:05:00  iter: 1639  total_loss: 0.2972  loss_cls: 0.06202  loss_box_reg: 0.1915  loss_rpn_cls: 0.001268  loss_rpn_loc: 0.002164  time: 0.3510  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:38 d2.utils.events]: [0m eta: 0:04:53  iter: 1659  total_loss: 0.2117  loss_cls: 0.0358  loss_box_reg: 0.1634  loss_rpn_cls: 0.001092  loss_rpn_loc: 0.001837  time: 0.3508  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:45 d2.utils.events]: [0m eta: 0:04:46  iter: 1679  total_loss: 0.2318  loss_cls: 0.06469  loss_box_reg: 0.1607  loss_rpn_cls: 0.0009267  loss_rpn_loc: 0.002765  time: 0.3507  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:52 d2.utils.events]: [0m eta: 0:04:39  iter: 1699  total_loss: 0.2407  loss_cls: 0.05662  loss_box_reg: 0.1666  loss_rpn_cls: 0.002405  loss_rpn_loc: 0.002795  time: 0.3507  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:48:58 d2.utils.events]: [0m eta: 0:04:32  iter: 1719  total_loss: 0.2132  loss_cls: 0.04543  loss_box_reg: 0.1565  loss_rpn_cls: 0.0007071  loss_rpn_loc: 0.002321  time: 0.3506  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:05 d2.utils.events]: [0m eta: 0:04:25  iter: 1739  total_loss: 0.2196  loss_cls: 0.05499  loss_box_reg: 0.1725  loss_rpn_cls: 0.001387  loss_rpn_loc: 0.002862  time: 0.3505  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:12 d2.utils.events]: [0m eta: 0:04:18  iter: 1759  total_loss: 0.2139  loss_cls: 0.04786  loss_box_reg: 0.1632  loss_rpn_cls: 0.0005202  loss_rpn_loc: 0.002421  time: 0.3505  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:19 d2.utils.events]: [0m eta: 0:04:11  iter: 1779  total_loss: 0.2277  loss_cls: 0.05077  loss_box_reg: 0.1696  loss_rpn_cls: 0.001124  loss_rpn_loc: 0.002107  time: 0.3504  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:26 d2.utils.events]: [0m eta: 0:04:04  iter: 1799  total_loss: 0.2151  loss_cls: 0.0449  loss_box_reg: 0.1728  loss_rpn_cls: 0.001544  loss_rpn_loc: 0.002756  time: 0.3503  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:33 d2.utils.events]: [0m eta: 0:03:57  iter: 1819  total_loss: 0.2426  loss_cls: 0.04593  loss_box_reg: 0.1659  loss_rpn_cls: 0.001464  loss_rpn_loc: 0.003248  time: 0.3503  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:40 d2.utils.events]: [0m eta: 0:03:50  iter: 1839  total_loss: 0.2436  loss_cls: 0.06065  loss_box_reg: 0.1749  loss_rpn_cls: 0.0008512  loss_rpn_loc: 0.002929  time: 0.3502  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:47 d2.utils.events]: [0m eta: 0:03:43  iter: 1859  total_loss: 0.2737  loss_cls: 0.0556  loss_box_reg: 0.1861  loss_rpn_cls: 0.001621  loss_rpn_loc: 0.002859  time: 0.3501  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:49:54 d2.utils.events]: [0m eta: 0:03:36  iter: 1879  total_loss: 0.2339  loss_cls: 0.04679  loss_box_reg: 0.163  loss_rpn_cls: 0.0008794  loss_rpn_loc: 0.002689  time: 0.3501  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:01 d2.utils.events]: [0m eta: 0:03:29  iter: 1899  total_loss: 0.2315  loss_cls: 0.05965  loss_box_reg: 0.1712  loss_rpn_cls: 0.001171  loss_rpn_loc: 0.00174  time: 0.3501  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:08 d2.utils.events]: [0m eta: 0:03:22  iter: 1919  total_loss: 0.2063  loss_cls: 0.05545  loss_box_reg: 0.1375  loss_rpn_cls: 0.001877  loss_rpn_loc: 0.002484  time: 0.3500  data_time: 0.0028  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:14 d2.utils.events]: [0m eta: 0:03:15  iter: 1939  total_loss: 0.2078  loss_cls: 0.04659  loss_box_reg: 0.1571  loss_rpn_cls: 0.001039  loss_rpn_loc: 0.002108  time: 0.3500  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:21 d2.utils.events]: [0m eta: 0:03:08  iter: 1959  total_loss: 0.2327  loss_cls: 0.04784  loss_box_reg: 0.1719  loss_rpn_cls: 0.002031  loss_rpn_loc: 0.002166  time: 0.3500  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:28 d2.utils.events]: [0m eta: 0:03:01  iter: 1979  total_loss: 0.2135  loss_cls: 0.05338  loss_box_reg: 0.1617  loss_rpn_cls: 0.0008515  loss_rpn_loc: 0.002021  time: 0.3499  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:35 d2.utils.events]: [0m eta: 0:02:54  iter: 1999  total_loss: 0.198  loss_cls: 0.04119  loss_box_reg: 0.1557  loss_rpn_cls: 0.0009283  loss_rpn_loc: 0.002722  time: 0.3498  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:42 d2.utils.events]: [0m eta: 0:02:47  iter: 2019  total_loss: 0.2079  loss_cls: 0.04871  loss_box_reg: 0.1587  loss_rpn_cls: 0.001759  loss_rpn_loc: 0.002582  time: 0.3498  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:49 d2.utils.events]: [0m eta: 0:02:40  iter: 2039  total_loss: 0.217  loss_cls: 0.04641  loss_box_reg: 0.1653  loss_rpn_cls: 0.001524  loss_rpn_loc: 0.003327  time: 0.3497  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:50:56 d2.utils.events]: [0m eta: 0:02:33  iter: 2059  total_loss: 0.2398  loss_cls: 0.05654  loss_box_reg: 0.1665  loss_rpn_cls: 0.001576  loss_rpn_loc: 0.002443  time: 0.3497  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:03 d2.utils.events]: [0m eta: 0:02:26  iter: 2079  total_loss: 0.1958  loss_cls: 0.04682  loss_box_reg: 0.1489  loss_rpn_cls: 0.0007984  loss_rpn_loc: 0.002576  time: 0.3496  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:10 d2.utils.events]: [0m eta: 0:02:19  iter: 2099  total_loss: 0.232  loss_cls: 0.0623  loss_box_reg: 0.1626  loss_rpn_cls: 0.001152  loss_rpn_loc: 0.002797  time: 0.3496  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:17 d2.utils.events]: [0m eta: 0:02:12  iter: 2119  total_loss: 0.2285  loss_cls: 0.07067  loss_box_reg: 0.1692  loss_rpn_cls: 0.00193  loss_rpn_loc: 0.0021  time: 0.3495  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:23 d2.utils.events]: [0m eta: 0:02:05  iter: 2139  total_loss: 0.2439  loss_cls: 0.05194  loss_box_reg: 0.1963  loss_rpn_cls: 0.001146  loss_rpn_loc: 0.003064  time: 0.3495  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:30 d2.utils.events]: [0m eta: 0:01:58  iter: 2159  total_loss: 0.2148  loss_cls: 0.05344  loss_box_reg: 0.1554  loss_rpn_cls: 0.0007276  loss_rpn_loc: 0.002338  time: 0.3494  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:37 d2.utils.events]: [0m eta: 0:01:51  iter: 2179  total_loss: 0.2186  loss_cls: 0.04424  loss_box_reg: 0.1657  loss_rpn_cls: 0.001032  loss_rpn_loc: 0.00202  time: 0.3494  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:44 d2.utils.events]: [0m eta: 0:01:44  iter: 2199  total_loss: 0.2097  loss_cls: 0.05391  loss_box_reg: 0.1407  loss_rpn_cls: 0.0009574  loss_rpn_loc: 0.002323  time: 0.3493  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:51 d2.utils.events]: [0m eta: 0:01:37  iter: 2219  total_loss: 0.228  loss_cls: 0.05465  loss_box_reg: 0.159  loss_rpn_cls: 0.0009497  loss_rpn_loc: 0.002278  time: 0.3493  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:51:58 d2.utils.events]: [0m eta: 0:01:30  iter: 2239  total_loss: 0.228  loss_cls: 0.04231  loss_box_reg: 0.177  loss_rpn_cls: 0.0009376  loss_rpn_loc: 0.002779  time: 0.3492  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:05 d2.utils.events]: [0m eta: 0:01:23  iter: 2259  total_loss: 0.2231  loss_cls: 0.0518  loss_box_reg: 0.1689  loss_rpn_cls: 0.0009216  loss_rpn_loc: 0.002199  time: 0.3492  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:12 d2.utils.events]: [0m eta: 0:01:16  iter: 2279  total_loss: 0.2234  loss_cls: 0.06014  loss_box_reg: 0.1565  loss_rpn_cls: 0.001619  loss_rpn_loc: 0.002568  time: 0.3492  data_time: 0.0027  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:19 d2.utils.events]: [0m eta: 0:01:09  iter: 2299  total_loss: 0.2096  loss_cls: 0.04143  loss_box_reg: 0.159  loss_rpn_cls: 0.0009696  loss_rpn_loc: 0.003109  time: 0.3491  data_time: 0.0024  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:26 d2.utils.events]: [0m eta: 0:01:02  iter: 2319  total_loss: 0.2192  loss_cls: 0.06209  loss_box_reg: 0.1484  loss_rpn_cls: 0.0009343  loss_rpn_loc: 0.002377  time: 0.3491  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:32 d2.utils.events]: [0m eta: 0:00:55  iter: 2339  total_loss: 0.1982  loss_cls: 0.05829  loss_box_reg: 0.1594  loss_rpn_cls: 0.001406  loss_rpn_loc: 0.002035  time: 0.3491  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:39 d2.utils.events]: [0m eta: 0:00:48  iter: 2359  total_loss: 0.2507  loss_cls: 0.04806  loss_box_reg: 0.1914  loss_rpn_cls: 0.001271  loss_rpn_loc: 0.002046  time: 0.3490  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:46 d2.utils.events]: [0m eta: 0:00:41  iter: 2379  total_loss: 0.2152  loss_cls: 0.05396  loss_box_reg: 0.153  loss_rpn_cls: 0.0007256  loss_rpn_loc: 0.00274  time: 0.3490  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:52:53 d2.utils.events]: [0m eta: 0:00:34  iter: 2399  total_loss: 0.2552  loss_cls: 0.06606  loss_box_reg: 0.1719  loss_rpn_cls: 0.001103  loss_rpn_loc: 0.002131  time: 0.3490  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:53:00 d2.utils.events]: [0m eta: 0:00:27  iter: 2419  total_loss: 0.2077  loss_cls: 0.04465  loss_box_reg: 0.1381  loss_rpn_cls: 0.0008069  loss_rpn_loc: 0.002445  time: 0.3489  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:53:07 d2.utils.events]: [0m eta: 0:00:20  iter: 2439  total_loss: 0.221  loss_cls: 0.04816  loss_box_reg: 0.1539  loss_rpn_cls: 0.0009028  loss_rpn_loc: 0.002667  time: 0.3489  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:53:14 d2.utils.events]: [0m eta: 0:00:13  iter: 2459  total_loss: 0.2187  loss_cls: 0.03683  loss_box_reg: 0.1642  loss_rpn_cls: 0.0006373  loss_rpn_loc: 0.002235  time: 0.3488  data_time: 0.0025  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:53:21 d2.utils.events]: [0m eta: 0:00:06  iter: 2479  total_loss: 0.1878  loss_cls: 0.04713  loss_box_reg: 0.1332  loss_rpn_cls: 0.00104  loss_rpn_loc: 0.001799  time: 0.3488  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:53:28 d2.utils.events]: [0m eta: 0:00:00  iter: 2499  total_loss: 0.2259  loss_cls: 0.04345  loss_box_reg: 0.1795  loss_rpn_cls: 0.0008177  loss_rpn_loc: 0.002851  time: 0.3488  data_time: 0.0026  lr: 0.00025  max_mem: 2283M
[32m[10/17 23:53:28 d2.engine.hooks]: [0mOverall training speed: 2498 iterations in 0:14:31 (0.3488 s / it)
[32m[10/17 23:53:28 d2.engine.hooks]: [0mTotal training time: 0:14:33 (0:00:02 on hooks)
[32m[10/17 23:53:28 d2.evaluation.coco_evaluation]: [0m'data' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[32m[10/17 23:53:28 d2.data.datasets.coco]: [0mConverting annotations of dataset 'data' to COCO format ...)
  0%|                                                   | 0/559 [00:00<?, ?it/s]  6%|██▍                                      | 34/559 [00:00<00:01, 332.83it/s] 13%|█████▏                                   | 70/559 [00:00<00:01, 346.10it/s] 19%|███████▌                                | 105/559 [00:00<00:01, 346.07it/s] 25%|██████████                              | 141/559 [00:00<00:01, 348.46it/s] 31%|████████████▌                           | 176/559 [00:00<00:01, 348.29it/s] 38%|███████████████                         | 211/559 [00:00<00:01, 345.77it/s] 44%|█████████████████▋                      | 247/559 [00:00<00:00, 350.09it/s] 51%|████████████████████▎                   | 283/559 [00:00<00:00, 352.53it/s] 57%|██████████████████████▊                 | 319/559 [00:00<00:00, 354.69it/s] 64%|█████████████████████████▌              | 357/559 [00:01<00:00, 361.02it/s] 71%|████████████████████████████▎           | 395/559 [00:01<00:00, 366.35it/s] 77%|██████████████████████████████▉         | 432/559 [00:01<00:00, 359.30it/s] 84%|█████████████████████████████████▌      | 469/559 [00:01<00:00, 361.32it/s] 91%|████████████████████████████████████▏   | 506/559 [00:01<00:00, 359.09it/s] 97%|██████████████████████████████████████▊ | 542/559 [00:01<00:00, 356.90it/s]100%|████████████████████████████████████████| 559/559 [00:01<00:00, 354.32it/s]
[32m[10/17 23:53:30 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[10/17 23:53:30 d2.data.datasets.coco]: [0mConversion finished, #images: 559, #annotations: 559
[32m[10/17 23:53:30 d2.data.datasets.coco]: [0mCaching COCO format annotations at './output/data_coco_format.json' ...
  0%|                                                   | 0/559 [00:00<?, ?it/s]  6%|██▋                                      | 36/559 [00:00<00:01, 355.95it/s] 13%|█████▎                                   | 72/559 [00:00<00:01, 352.99it/s] 19%|███████▋                                | 108/559 [00:00<00:01, 348.79it/s] 26%|██████████▌                             | 147/559 [00:00<00:01, 362.34it/s] 33%|█████████████▏                          | 184/559 [00:00<00:01, 360.91it/s] 40%|███████████████▊                        | 221/559 [00:00<00:00, 357.57it/s] 46%|██████████████████▍                     | 258/559 [00:00<00:00, 358.61it/s] 53%|█████████████████████                   | 294/559 [00:00<00:00, 357.80it/s] 60%|███████████████████████▊                | 333/559 [00:00<00:00, 364.97it/s] 67%|██████████████████████████▌             | 372/559 [00:01<00:00, 371.00it/s] 73%|█████████████████████████████▎          | 410/559 [00:01<00:00, 365.61it/s] 80%|███████████████████████████████▉        | 447/559 [00:01<00:00, 361.75it/s] 87%|██████████████████████████████████▋     | 484/559 [00:01<00:00, 359.69it/s] 93%|█████████████████████████████████████▎  | 521/559 [00:01<00:00, 359.46it/s]100%|███████████████████████████████████████▊| 557/559 [00:01<00:00, 354.78it/s]100%|████████████████████████████████████████| 559/559 [00:01<00:00, 358.93it/s]
[32m[10/17 23:53:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[10/17 23:53:32 d2.data.common]: [0mSerializing 559 elements to byte tensors and concatenating them all ...
[32m[10/17 23:53:32 d2.data.common]: [0mSerialized dataset takes 0.19 MiB
[32m[10/17 23:53:32 d2.evaluation.evaluator]: [0mStart inference on 559 batches
[32m[10/17 23:53:34 d2.evaluation.evaluator]: [0mInference done 11/559. Dataloading: 0.0007 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1818 s/iter. ETA=0:01:39
[32m[10/17 23:53:39 d2.evaluation.evaluator]: [0mInference done 39/559. Dataloading: 0.0009 s/iter. Inference: 0.1818 s/iter. Eval: 0.0001 s/iter. Total: 0.1829 s/iter. ETA=0:01:35
[32m[10/17 23:53:44 d2.evaluation.evaluator]: [0mInference done 61/559. Dataloading: 0.0010 s/iter. Inference: 0.2008 s/iter. Eval: 0.0001 s/iter. Total: 0.2019 s/iter. ETA=0:01:40
[32m[10/17 23:53:49 d2.evaluation.evaluator]: [0mInference done 86/559. Dataloading: 0.0010 s/iter. Inference: 0.2012 s/iter. Eval: 0.0001 s/iter. Total: 0.2024 s/iter. ETA=0:01:35
[32m[10/17 23:53:54 d2.evaluation.evaluator]: [0mInference done 110/559. Dataloading: 0.0009 s/iter. Inference: 0.2028 s/iter. Eval: 0.0001 s/iter. Total: 0.2040 s/iter. ETA=0:01:31
[32m[10/17 23:53:59 d2.evaluation.evaluator]: [0mInference done 137/559. Dataloading: 0.0009 s/iter. Inference: 0.1991 s/iter. Eval: 0.0001 s/iter. Total: 0.2003 s/iter. ETA=0:01:24
[32m[10/17 23:54:04 d2.evaluation.evaluator]: [0mInference done 162/559. Dataloading: 0.0009 s/iter. Inference: 0.2004 s/iter. Eval: 0.0001 s/iter. Total: 0.2016 s/iter. ETA=0:01:20
[32m[10/17 23:54:09 d2.evaluation.evaluator]: [0mInference done 192/559. Dataloading: 0.0009 s/iter. Inference: 0.1955 s/iter. Eval: 0.0001 s/iter. Total: 0.1967 s/iter. ETA=0:01:12
[32m[10/17 23:54:15 d2.evaluation.evaluator]: [0mInference done 220/559. Dataloading: 0.0009 s/iter. Inference: 0.1940 s/iter. Eval: 0.0001 s/iter. Total: 0.1952 s/iter. ETA=0:01:06
[32m[10/17 23:54:20 d2.evaluation.evaluator]: [0mInference done 243/559. Dataloading: 0.0009 s/iter. Inference: 0.1967 s/iter. Eval: 0.0001 s/iter. Total: 0.1978 s/iter. ETA=0:01:02
[32m[10/17 23:54:25 d2.evaluation.evaluator]: [0mInference done 272/559. Dataloading: 0.0009 s/iter. Inference: 0.1942 s/iter. Eval: 0.0001 s/iter. Total: 0.1954 s/iter. ETA=0:00:56
[32m[10/17 23:54:30 d2.evaluation.evaluator]: [0mInference done 301/559. Dataloading: 0.0009 s/iter. Inference: 0.1921 s/iter. Eval: 0.0001 s/iter. Total: 0.1933 s/iter. ETA=0:00:49
[32m[10/17 23:54:35 d2.evaluation.evaluator]: [0mInference done 323/559. Dataloading: 0.0009 s/iter. Inference: 0.1948 s/iter. Eval: 0.0001 s/iter. Total: 0.1959 s/iter. ETA=0:00:46
[32m[10/17 23:54:40 d2.evaluation.evaluator]: [0mInference done 346/559. Dataloading: 0.0009 s/iter. Inference: 0.1964 s/iter. Eval: 0.0001 s/iter. Total: 0.1975 s/iter. ETA=0:00:42
[32m[10/17 23:54:45 d2.evaluation.evaluator]: [0mInference done 374/559. Dataloading: 0.0009 s/iter. Inference: 0.1951 s/iter. Eval: 0.0001 s/iter. Total: 0.1963 s/iter. ETA=0:00:36
[32m[10/17 23:54:50 d2.evaluation.evaluator]: [0mInference done 398/559. Dataloading: 0.0009 s/iter. Inference: 0.1960 s/iter. Eval: 0.0001 s/iter. Total: 0.1971 s/iter. ETA=0:00:31
[32m[10/17 23:54:55 d2.evaluation.evaluator]: [0mInference done 425/559. Dataloading: 0.0009 s/iter. Inference: 0.1953 s/iter. Eval: 0.0001 s/iter. Total: 0.1965 s/iter. ETA=0:00:26
[32m[10/17 23:55:00 d2.evaluation.evaluator]: [0mInference done 447/559. Dataloading: 0.0009 s/iter. Inference: 0.1970 s/iter. Eval: 0.0001 s/iter. Total: 0.1982 s/iter. ETA=0:00:22
[32m[10/17 23:55:05 d2.evaluation.evaluator]: [0mInference done 469/559. Dataloading: 0.0009 s/iter. Inference: 0.1985 s/iter. Eval: 0.0001 s/iter. Total: 0.1996 s/iter. ETA=0:00:17
[32m[10/17 23:55:11 d2.evaluation.evaluator]: [0mInference done 497/559. Dataloading: 0.0009 s/iter. Inference: 0.1977 s/iter. Eval: 0.0001 s/iter. Total: 0.1988 s/iter. ETA=0:00:12
[32m[10/17 23:55:16 d2.evaluation.evaluator]: [0mInference done 524/559. Dataloading: 0.0009 s/iter. Inference: 0.1973 s/iter. Eval: 0.0001 s/iter. Total: 0.1985 s/iter. ETA=0:00:06
[32m[10/17 23:55:21 d2.evaluation.evaluator]: [0mInference done 550/559. Dataloading: 0.0009 s/iter. Inference: 0.1974 s/iter. Eval: 0.0001 s/iter. Total: 0.1985 s/iter. ETA=0:00:01
[32m[10/17 23:55:22 d2.evaluation.evaluator]: [0mTotal inference time: 0:01:49.734863 (0.198077 s / iter per device, on 1 devices)
[32m[10/17 23:55:22 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:01:49 (0.196772 s / iter per device, on 1 devices)
[32m[10/17 23:55:22 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[10/17 23:55:22 d2.evaluation.coco_evaluation]: [0mSaving results to ./output/coco_instances_results.json
[32m[10/17 23:55:22 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[32m[10/17 23:55:22 d2.evaluation.fast_eval_api]: [0mEvaluate annotation type *bbox*
[32m[10/17 23:55:23 d2.evaluation.fast_eval_api]: [0mCOCOeval_opt.evaluate() finished in 0.04 seconds.
[32m[10/17 23:55:23 d2.evaluation.fast_eval_api]: [0mAccumulating evaluation results...
[32m[10/17 23:55:23 d2.evaluation.fast_eval_api]: [0mCOCOeval_opt.accumulate() finished in 0.00 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.742
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.811
[32m[10/17 23:55:23 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.932 | 57.310 | 50.049 | 36.353 | 39.452 | 48.739 |
